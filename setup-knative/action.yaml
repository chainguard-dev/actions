# Copyright 2022 Chainguard, Inc.
# SPDX-License-Identifier: Apache-2.0

name: 'Setup Knative'
description: |
  This action sets up Knative Serving and Eventing on the current
  kubectl context (typically KinD from setup-kind).

inputs:
  version:
    description: |
      The minor version of Knative to install, e.g. 1.2.0
    required: true
    default: 1.2.0

  kingress:
    description: |
      The Knative ingress layer to install, e.g. kourier, istio
    required: true
    default: "kourier"

  serving-features:
    description: |
      The serialized JSON for the Knative Serving features configmap
      containing the features to be enabled, e.g.
        {"kubernetes.podspec-fieldref":"enabled"}
    required: true
    default: '{}'

  serving-defaults:
    description: |
      The serialized JSON for the Knative Serving defaults configmap
      containing the desired default values, e.g.
        {"revision-timeout-seconds":"120"}
    required: true
    default: '{}'

  serving-autoscaler:
    description: |
      The serialized JSON for the Knative Serving autoscaling configmap
      containing the desired settings, e.g.
        {"min-scale":"1"}
    required: true
    default: '{}'

outputs:
  load-balancer-ip:
    description: |
      The IP of the type LoadBalancer service on which knative serves.
    value: ${{ steps.knative.outputs.load-balancer-ip }}

runs:
  using: "composite"

  steps:
    - name: Install Knative
      id: knative
      shell: bash
      run: |
        # Eliminates the resources blocks in a release yaml
        function resource_blaster() {
          local REPO="${1}"
          local FILE="${2}"

          curl -L -s "https://github.com/knative/${REPO}/releases/download/knative-v${{ inputs.version }}/${FILE}" \
            | yq e 'del(.spec.template.spec.containers[]?.resources)' - \
            `# Filter out empty objects that come out as {} b/c kubectl barfs` \
            | grep -v '^{}$'
        }

        # Validate we have a valid kingress, and install its CRDs.
        case "${{ inputs.kingress }}" in
          "istio")
            # If we're using Istio, then install the Istio CRDs first.
            resource_blaster net-istio istio.yaml | ko resolve -l knative.dev/crd-install=true -f - | kubectl apply -f -
            ;;
          "kourier")
            # Supported, but doesn't have CRDs to install.
            ;;
          *)
            echo Unsupported ingress ${{ inputs.kingress }} ;
            exit 1 ;;
        esac

        resource_blaster serving serving-crds.yaml | kubectl apply -f -
        resource_blaster eventing eventing-crds.yaml | kubectl apply -f -

        sleep 3 # Avoid the race creating CRDs then instantiating them...

        resource_blaster serving serving-core.yaml | kubectl apply -f -
        resource_blaster eventing eventing-core.yaml | kubectl apply -f -
        case "${{ inputs.kingress }}" in
          "istio")
            resource_blaster net-istio istio.yaml | kubectl apply -f -
            resource_blaster net-istio net-istio.yaml | kubectl apply -f -
            ;;
          "kourier")
            resource_blaster net-kourier kourier.yaml | kubectl apply -f -
            ;;
        esac
        kubectl patch configmap/config-network \
          --namespace knative-serving \
          --type merge \
          --patch '{"data":{"ingress.class":"${{ inputs.kingress }}.ingress.networking.knative.dev","autocreateClusterDomainClaims":"true"}}'

        resource_blaster eventing in-memory-channel.yaml | kubectl apply -f -
        resource_blaster eventing mt-channel-broker.yaml | kubectl apply -f -

        cat | kubectl apply -f - <<EOF
        apiVersion: v1
        kind: ConfigMap
        metadata:
          name: imc-channel
          namespace: knative-eventing
        data:
          channelTemplateSpec: |
            apiVersion: messaging.knative.dev/v1
            kind: InMemoryChannel
        ---
        apiVersion: v1
        kind: ConfigMap
        metadata:
          name: config-br-defaults
          namespace: knative-eventing
        data:
          default-br-config: |
            # This is the cluster-wide default broker channel.
            clusterDefault:
              brokerClass: MTChannelBasedBroker
              apiVersion: v1
              kind: ConfigMap
              name: imc-channel
              namespace: knative-eventing
        EOF

        # Wait for Knative to be ready (or webhook will reject services)
        for x in $(kubectl get deploy --namespace knative-serving -oname); do
          kubectl rollout status --timeout 5m --namespace knative-serving $x
        done
        for x in $(kubectl get deploy --namespace knative-eventing -oname); do
          kubectl rollout status --timeout 5m --namespace knative-eventing $x
        done

        while ! kubectl patch configmap/config-features \
          --namespace knative-serving \
          --type merge \
          --patch '{"data":${{ inputs.serving-features }}}'
        do
            echo Waiting for webhook to be up.
            sleep 1
        done

        while ! kubectl patch configmap/config-defaults \
          --namespace knative-serving \
          --type merge \
          --patch '{"data":${{ inputs.serving-defaults }}}'
        do
            echo Waiting for webhook to be up.
            sleep 1
        done

        while ! kubectl patch configmap/config-autoscaler \
          --namespace knative-serving \
          --type merge \
          --patch '{"data":${{ inputs.serving-autoscaler }}}'
        do
            echo Waiting for webhook to be up.
            sleep 1
        done

        # Enable magic dns so we can interact with services from actions.
        resource_blaster serving serving-default-domain.yaml | kubectl apply -f -

        # Wait for the job to complete, so we can reliably use ksvc hostnames.
        kubectl wait -n knative-serving --timeout=90s --for=condition=Complete jobs --all

        # Add an output for the IP of the LoadBalancer to avoid folks assuming stuff.
        case "${{ inputs.kingress }}" in
          "istio")
            export IP=$(kubectl get svc -n istio-system istio-ingressgateway -ojsonpath={.status.loadBalancer.ingress[0].ip})
            ;;
          "kourier")
            export IP=$(kubectl get svc -n kourier-system kourier -ojsonpath={.status.loadBalancer.ingress[0].ip})
            ;;
        esac
        echo LB IP: ${IP}
        echo ::set-output name=load-balancer-ip::${IP}
