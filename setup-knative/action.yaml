# Copyright 2022 Chainguard, Inc.
# SPDX-License-Identifier: Apache-2.0

name: 'Setup Knative'
description: |
  This action sets up Knative Serving and Eventing on the current
  kubectl context (typically KinD from setup-kind).

inputs:
  version:
    description: |
      The minor version of Knative to install, e.g. 1.2.0
    required: true
    default: 1.2.0

  kingress:
    description: |
      The Knative ingress layer to install, e.g. kourier, istio
    required: true
    default: "kourier"

  cluster-domain:
    description: |
      The cluster domain suffix, defaults to cluster.local
    required: false
    default: "cluster.local"

  serving-features:
    description: |
      The serialized JSON for the Knative Serving features configmap
      containing the features to be enabled, e.g.
        {"kubernetes.podspec-fieldref":"enabled"}
    required: true
    default: '{}'

  serving-defaults:
    description: |
      The serialized JSON for the Knative Serving defaults configmap
      containing the desired default values, e.g.
        {"revision-timeout-seconds":"120"}
    required: true
    default: '{}'

  serving-autoscaler:
    description: |
      The serialized JSON for the Knative Serving autoscaling configmap
      containing the desired settings, e.g.
        {"min-scale":"1"}
    required: true
    default: '{}'

outputs:
  load-balancer-ip:
    description: |
      The IP of the type LoadBalancer service on which knative serves.
    value: ${{ steps.knative.outputs.load-balancer-ip }}

runs:
  using: "composite"

  steps:
    - name: Install Knative
      id: knative
      shell: bash
      run: |
        # Eliminates the resources blocks in a release yaml
        function resource_blaster() {
          local REPO="${1}"
          local FILE="${2}"

          curl -L -s "https://github.com/knative/${REPO}/releases/download/knative-v${{ inputs.version }}/${FILE}" \
            | yq e 'del(.spec.template.spec.containers[]?.resources)' - \
            `# Filter out empty objects that come out as {} b/c kubectl barfs` \
            | grep -v '^{}$'
        }

        function download_istioctl() {
          ISTIO_VERSION=1.14.0
          ISTIO_BASE_URL="https://github.com/istio/istio/releases/download"
          case "$(echo $RUNNER_OS | awk '{print tolower($0)}')" in
          "linux") OS=linux;;
          "macos") OS=osx;;
          *)
            echo Unsupported RUNNER_OS \"$RUNNER_OS\";
            exit -1;;
          esac
          ISTIO_URL=${ISTIO_BASE_URL}/${ISTIO_VERSION}/istio-${ISTIO_VERSION}-${OS}-$(arch).tar.gz
          wget -v $ISTIO_URL -O istio.tar.gz
          tar xvzf istio.tar.gz
        }

        # Validate we have a valid kingress, and install its CRDs.
        case "${{ inputs.kingress }}" in
          "istio")
            download_istioctl
            cat > istio-profile.yaml <<EOF
        apiVersion: install.istio.io/v1alpha1
        kind: IstioOperator
        spec:
          values:
            global:
              # Ideally for KinD installations we want to blow away the `resources`
              # sections. However, doing that here will result in Istio's default which
              # is high. Choosing some nomimal small numbers here:
              defaultResources: &defaultResources
                requests:
                  cpu: 1m
                  memory: 10Mi
              proxy:
                clusterDomain: ${{ inputs.cluster-domain }}
                resources: *defaultResources

          meshConfig:
            defaultConfig:
              terminationDrainDuration: "20s"

          components:
            ingressGateways:
              - name: istio-ingressgateway
                k8s: &defaultK8s
                  hpaSpec:
                    maxReplicas: 1
                    minReplicas: 1
                  resources: *defaultResources
            pilot:
              k8s: *defaultK8s
        EOF
            ./istio-${ISTIO_VERSION}/bin/istioctl install --skip-confirmation -f istio-profile.yaml
            ;;
          "kourier")
            # Supported, but doesn't have CRDs to install.
            ;;
          *)
            echo Unsupported ingress ${{ inputs.kingress }} ;
            exit 1 ;;
        esac

        resource_blaster serving serving-crds.yaml | kubectl apply -f -
        resource_blaster eventing eventing-crds.yaml | kubectl apply -f -

        sleep 3 # Avoid the race creating CRDs then instantiating them...

        resource_blaster serving serving-core.yaml | kubectl apply -f -
        resource_blaster eventing eventing-core.yaml | kubectl apply -f -
        case "${{ inputs.kingress }}" in
          "istio")
            resource_blaster net-istio net-istio.yaml | kubectl apply -f -
            ;;
          "kourier")
            resource_blaster net-kourier kourier.yaml | kubectl apply -f -
            ;;
        esac
        kubectl patch configmap/config-network \
          --namespace knative-serving \
          --type merge \
          --patch '{"data":{"ingress.class":"${{ inputs.kingress }}.ingress.networking.knative.dev","autocreateClusterDomainClaims":"true"}}'

        resource_blaster eventing in-memory-channel.yaml | kubectl apply -f -
        resource_blaster eventing mt-channel-broker.yaml | kubectl apply -f -

        cat | kubectl apply -f - <<EOF
        apiVersion: v1
        kind: ConfigMap
        metadata:
          name: imc-channel
          namespace: knative-eventing
        data:
          channelTemplateSpec: |
            apiVersion: messaging.knative.dev/v1
            kind: InMemoryChannel
        ---
        apiVersion: v1
        kind: ConfigMap
        metadata:
          name: config-br-defaults
          namespace: knative-eventing
        data:
          default-br-config: |
            # This is the cluster-wide default broker channel.
            clusterDefault:
              brokerClass: MTChannelBasedBroker
              apiVersion: v1
              kind: ConfigMap
              name: imc-channel
              namespace: knative-eventing
        EOF

        # Wait for Knative to be ready (or webhook will reject services)
        for x in $(kubectl get deploy --namespace knative-serving -oname); do
          kubectl rollout status --timeout 5m --namespace knative-serving $x
        done
        for x in $(kubectl get deploy --namespace knative-eventing -oname); do
          kubectl rollout status --timeout 5m --namespace knative-eventing $x
        done

        while ! kubectl patch configmap/config-features \
          --namespace knative-serving \
          --type merge \
          --patch '{"data":${{ inputs.serving-features }}}'
        do
            echo Waiting for webhook to be up.
            sleep 1
        done

        while ! kubectl patch configmap/config-defaults \
          --namespace knative-serving \
          --type merge \
          --patch '{"data":${{ inputs.serving-defaults }}}'
        do
            echo Waiting for webhook to be up.
            sleep 1
        done

        while ! kubectl patch configmap/config-autoscaler \
          --namespace knative-serving \
          --type merge \
          --patch '{"data":${{ inputs.serving-autoscaler }}}'
        do
            echo Waiting for webhook to be up.
            sleep 1
        done

        # Enable magic dns so we can interact with services from actions.
        resource_blaster serving serving-default-domain.yaml | kubectl apply -f -

        # Wait for the job to complete, so we can reliably use ksvc hostnames.
        kubectl wait -n knative-serving --timeout=90s --for=condition=Complete jobs --all

        # Add an output for the IP of the LoadBalancer to avoid folks assuming stuff.
        case "${{ inputs.kingress }}" in
          "istio")
            export IP=$(kubectl get svc -n istio-system istio-ingressgateway -ojsonpath={.status.loadBalancer.ingress[0].ip})
            ;;
          "kourier")
            export IP=$(kubectl get svc -n kourier-system kourier -ojsonpath={.status.loadBalancer.ingress[0].ip})
            ;;
        esac
        echo LB IP: ${IP}
        echo ::set-output name=load-balancer-ip::${IP}
